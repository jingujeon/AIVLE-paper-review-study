![image](https://github.com/user-attachments/assets/cbf73603-c565-4127-a47b-efda8c59759a)## ğŸ“š DeepLearner

AIVLE 7ê¸° 3/4ë°˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ,  
AIì™€ ê´€ë ¨ëœ ë…¼ë¬¸ì„ í•¨ê»˜ ì½ê³  ë°œí‘œí•˜ëŠ” ìŠ¤í„°ë””ì…ë‹ˆë‹¤.

ë…¼ë¬¸ì€ ì•„í‚¤í…ì²˜, NLP, ì»´í“¨í„° ë¹„ì „ ë“±  
AIì˜ ë‹¤ì–‘í•œ ë¶„ì•¼ë¥¼ í­ë„“ê²Œ ë‹¤ë£¨ë©°,  
ê¸°ì´ˆ ì´ë¡ ë¶€í„° ìµœê·¼ íŠ¸ë Œë“œê¹Œì§€ ê· í˜• ìˆê²Œ ì„ ì •í•©ë‹ˆë‹¤.

ë°œí‘œ ìë£Œì™€ ë…¼ë¬¸ PDFëŠ” GitHubì— ì£¼ì°¨ë³„ë¡œ ì •ë¦¬í•´ ê¸°ë¡í•©ë‹ˆë‹¤.

> âœ… **ë°œí‘œ ë‚ ì§œ**ë¥¼ í´ë¦­í•˜ë©´ ë°œí‘œ ìë£Œë¡œ,  
> **ë…¼ë¬¸ ì œëª©**ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ë…¼ë¬¸ì´ ê²Œì‹œëœ ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤!

---

| ë°œí‘œ ë‚ ì§œ | ë…¼ë¬¸ ì œëª© | ë°œí–‰ ì—°ì›” | ë°œí‘œì²˜ | ë°œí‘œì |
|-----------|------------|-----------|--------|--------|
| [250501](presentations/250501/20250501_%EC%A0%84%EC%A7%84%EA%B5%AC_Ichigo%20Mixed-Modal%20Early-Fusion%20Realtime%20Voice%20Assistant.pdf) | [Ichigo Mixed-Modal Early-Fusion Realtime Voice Assistant](https://paperswithcode.com/paper/ichigo-mixed-modal-early-fusion-realtime) | 2024-10 | preprint | ì „ì§„êµ¬ |
| [250508](presentations/250508/20250508_%EB%82%A8%EA%B2%BD%ED%83%81_Novel%20View%20Synthesis.pdf) | [Grounding Image Matching in 3D with MASt3R](https://eccv.ecva.net/virtual/2024/poster/523) | 2024-06 | ECCV | ë‚¨ê²½íƒ |
| [250515](presentations/250515/20250515_%EB%B0%95%EA%B8%B0%EC%9B%85_Are%20Transformers%20Effective%20for%20Time%20Series%20Forecasting.pdf) | [Are Transformers Effective for Time Series Forecasting?](https://ojs.aaai.org/index.php/AAAI/article/view/26317) | 2023-06 | AAAI | ë°•ê¸°ì›… |
| [250515](presentations/250515/20250515_%EC%95%88%EB%8F%84%ED%98%95_Retrieval-Augmented%20Generation%20for%20Knowledge-Intensive%20NLP%20Tasks.pdf) | [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://neurips.cc/virtual/2020/protected/poster_6b493230205f780e1bc26945df7481e5.html) | 2020-12 | NeurIPS | ì•ˆë„í˜• |
| [250522](presentations/250522/20250522_%EA%B9%80%EC%B0%AC%EC%A7%84_Segment%20Anything.pdf) | [Segment Anything](https://ai.meta.com/research/publications/segment-anything/) | 2023-05 | preprint | ê¹€ì°¬ì§„ |
| [250522](presentations/250522/20250522_%EC%9E%A5%EC%9E%90%EC%9C%A4_Segment%20Anything_Mixture-of-Agents%20Enhances%20Large%20Language%20Model%20Capabilities.pdf) | [Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/abs/2406.04692) | 2024-06 | preprint | ì¥ììœ¤ |
| [250529](presentations/250529/20250529_%ED%99%8D%EA%B6%8C_TextRefiner%20Internal%20Visual%20Feature%20as%20Efficient%20Refiner%20for%20Vision-Language%20Models%20Prompt%20Tuning.pdf) | [TextRefiner: Internal Visual Feature as Efficient Refiner for Vision-Language Models Prompt Tuning](https://ojs.aaai.org/index.php/AAAI/article/view/32942) | 2025-04 | AAAI | í™ê¶Œ |
| [250529](presentations/250529/20250529_%EC%9D%B4%EC%9C%A0%EB%AF%BC_Don't%20Do%20RAG%20When%20Cache-Augmented%20Generation%20is%20All%20You%20Need%20for%20Knowledge%20Tasks.pdf) | [Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks](https://arxiv.org/abs/2412.15605) | 2024-12 | preprint | ì´ìœ ë¯¼ |
| [250605](presentations/250605/250605_%EC%A0%84%EC%A7%84%EA%B5%AC_Chameleon%20Mixed-Modal%20Early-Fusion%20Foundation%20Models.pdf) | [Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://arxiv.org/abs/2405.09818) | 2024-05 | preprint | ì „ì§„êµ¬ |
| [250619](presentations/250619/250619_%EB%82%A8%EA%B2%BD%ED%83%81_Attention%20Is%20All%20You%20Need.pdf) | [Attention Is All You Need](https://arxiv.org/abs/1706.03762) | 2017-06 | NeurIPS | ë‚¨ê²½íƒ |
| [250626](presentations/250626/250626_%EC%9E%A5%EC%9E%90%EC%9C%A4_LiveCC-Learning%20Video%20LLM%20with%20Streaming%20Speech%20Transcription%20at%20Scale.pdf) | [LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale](https://arxiv.org/abs/2504.16030) | 2025-04 | CVPR | ì¥ììœ¤ |
| [250626](presentations/250626/250626_%EB%B0%95%EA%B8%B0%EC%9B%85_BRITS-Bidirectional%20Recurrent%20Imputation%20for%20Time%20Series.pdf) | [BRITS: Bidirectional Recurrent Imputation for Time Series](https://arxiv.org/abs/1805.10572) | 2018-05 | NeurIPS | ë°•ê¸°ì›… |
| [250626](presentations/250626/250626_%EA%B9%80%EC%B0%AC%EC%A7%84_SAM%202-Segment%20Anything%20in%20Images%20and%20Videos.pdf) | [SAM 2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714) | 2024-08 | preprint | ê¹€ì°¬ì§„ |
| [250703](presentations/250703/250703_%EC%95%88%EB%8F%84%ED%98%95_REPLUG-Retrieval-Augmented%20Black-Box%20Language%20Models.pdf) | [REPLUG: Retrieval-Augmented Black-Box Language Models](https://arxiv.org/abs/2301.12652) | 2023-1 | NAACL | ì•ˆë„í˜• |
| [250703](presentations/250703/250703_%ED%99%8D%EA%B6%8C_MATCHA-Towards%20Matching%20Anything.pdf) | [MATCHA:Towards Matching Anything](https://arxiv.org/abs/2501.14945) | 2025-06 | CVPR | í™ê¶Œ |
| [250703](presentations/250703/250703_%EC%9D%B4%EC%9C%A0%EB%AF%BC_Reinforcement%20Pre-Training.pdf) | [Reinforcement Pre-Training](https://arxiv.org/abs/2506.08007) | 2025-01 | preprint | ì´ìœ ë¯¼ |

---
