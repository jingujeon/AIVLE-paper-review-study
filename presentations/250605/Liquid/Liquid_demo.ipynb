{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jguoCKE192EV","outputId":"0972e4fb-9e25-4cb8-b5ca-61396b21aa20","executionInfo":{"status":"ok","timestamp":1749126792196,"user_tz":-540,"elapsed":19120,"user":{"displayName":"전진구","userId":"15391197455953273384"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Google Drive를 마운트합니다...\n","Mounted at /content/drive\n","Google Drive 마운트 완료.\n"]}],"source":["from google.colab import drive\n","import os\n","\n","print(\"Google Drive를 마운트합니다...\")\n","drive.mount('/content/drive')\n","print(\"Google Drive 마운트 완료.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":649,"status":"ok","timestamp":1749048926432,"user":{"displayName":"전진구","userId":"15391197455953273384"},"user_tz":-540},"id":"sT5tt3TG-CKN","outputId":"87041f6c-40ca-4d51-b80f-f5fef6f05816"},"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리: /content\n","워크스페이스 내용:\n","total 20\n","drwxr-xr-x 1 root root 4096 Jun  4 14:55 .\n","drwxr-xr-x 1 root root 4096 Jun  4 14:49 ..\n","drwxr-xr-x 4 root root 4096 Jun  2 13:38 .config\n","drwx------ 6 root root 4096 Jun  4 14:55 drive\n","drwxr-xr-x 1 root root 4096 Jun  2 13:39 sample_data\n","\n","✅ 로컬 '/content/drive/MyDrive/Liquid' 폴더가 발견되었습니다.\n","GitHub에서 다시 다운로드할 필요 없이 기존 폴더를 사용합니다.\n","/content/drive/MyDrive/Liquid\n","현재 작업 디렉토리: /content/drive/MyDrive/Liquid\n","\n","Liquid 루트 폴더 내용:\n","total 123\n","drwx------ 2 root root  4096 Jun  3 09:18 assets\n","-rw------- 1 root root  4330 Jun  3 09:18 Data.md\n","drwx------ 2 root root  4096 Jun  3 09:18 data_process\n","drwx------ 2 root root  4096 Jun  3 09:18 evaluation\n","drwx------ 2 root root  4096 Jun  3 09:18 .git\n","-rw------- 1 root root    59 Jun  3 09:18 .gitignore\n","drwx------ 2 root root  4096 Jun  3 11:03 .ipynb_checkpoints\n","-rw------- 1 root root  1073 Jun  3 09:18 LICENSE\n","drwx------ 2 root root  4096 Jun  3 09:18 liquid\n","-rw------- 1 root root 71443 Jun  4 14:55 Liquid_demo.ipynb\n","drwx------ 2 root root  4096 Jun  3 11:49 liquid.egg-info\n","drwx------ 2 root root  4096 Jun  3 11:03 models\n","-rw------- 1 root root  1347 Jun  3 12:02 pyproject.toml\n","-rw------- 1 root root  5555 Jun  3 09:18 README.md\n","drwx------ 2 root root  4096 Jun  3 09:18 scripts\n","-rw------- 1 root root  3184 Jun  3 09:18 TRAIN.md\n","\n","✅ pyproject.toml과 Liquid 폴더가 모두 확인되었습니다!\n"]}],"source":["# 로컬 Liquid 저장소 경로 확인\n","import os\n","\n","# 현재 워크스페이스 디렉토리 확인\n","print(\"현재 작업 디렉토리:\", os.getcwd())\n","print(\"워크스페이스 내용:\")\n","!ls -la\n","\n","# 로컬 Liquid 루트 폴더 확인 (Liquid 하위 폴더가 아니라 루트!)\n","Liquid_root_path = '/content/drive/MyDrive/Liquid'\n","\n","if os.path.exists(Liquid_root_path):\n","    print(f\"\\n✅ 로컬 '{Liquid_root_path}' 폴더가 발견되었습니다.\")\n","    print(\"GitHub에서 다시 다운로드할 필요 없이 기존 폴더를 사용합니다.\")\n","\n","    # Liquid 루트 폴더로 작업 디렉토리 변경\n","    %cd {Liquid_root_path}\n","    print(f\"현재 작업 디렉토리: {os.getcwd()}\")\n","\n","    # 폴더 내용 확인\n","    print(\"\\nLiquid 루트 폴더 내용:\")\n","    !ls -la\n","\n","    # pyproject.toml과 Liquid 하위 폴더가 모두 있는지 확인\n","    if os.path.exists('pyproject.toml') and os.path.exists('liquid'):\n","        print(\"\\n✅ pyproject.toml과 Liquid 폴더가 모두 확인되었습니다!\")\n","    else:\n","        print(\"\\n⚠️ pyproject.toml 또는 liquid 폴더가 누락되었습니다.\")\n","\n","else:\n","    print(f\"\\n❌ 오류: '{Liquid_root_path}' 폴더를 찾을 수 없습니다.\")\n","    print(\"현재 워크스페이스에 Liquid 폴더가 있는지 확인해주세요.\")"]},{"cell_type":"code","source":["# Liquid 프로젝트 설치\n","%cd /content/drive/MyDrive/Liquid\n","!pip install -e . --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erfkD8pItNoK","executionInfo":{"status":"ok","timestamp":1749049101213,"user_tz":-540,"elapsed":173370,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"ba5f745d-2d03-47c8-bdca-c584007bae17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Liquid\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building editable for liquid (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-genai 1.17.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.24.0 which is incompatible.\n","google-genai 1.17.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n","gradio-client 1.10.1 requires httpx>=0.24.1, but you have httpx 0.24.0 which is incompatible.\n","albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n","imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n","mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n","langchain 0.3.25 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n","gradio 5.31.0 requires httpx>=0.24.1, but you have httpx 0.24.0 which is incompatible.\n","gradio 5.31.0 requires pydantic<2.12,>=2.0, but you have pydantic 1.10.22 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\n","sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.2 which is incompatible.\n","langchain-core 0.3.63 requires pydantic>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Flash Attention 설치\n","!pip install packaging ninja --quiet\n","!pip install flash-attn==2.5.8 --no-build-isolation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yC79lezftXYR","executionInfo":{"status":"ok","timestamp":1749049162418,"user_tz":-540,"elapsed":18759,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"8fd341f6-3bb1-4e1a-b2e1-19c44d2b0984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flash-attn==2.5.8\n","  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.5.8) (2.1.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.5.8) (0.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.5.8) (24.2)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from flash-attn==2.5.8) (1.11.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn==2.5.8) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn==2.5.8) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn==2.5.8) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn==2.5.8) (1.3.0)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.5.8-cp311-cp311-linux_x86_64.whl size=120632803 sha256=cfaacc2cf003cadc7bf473cae88d0a668d191dd40b51f28ba165ccefe15bcca9\n","  Stored in directory: /root/.cache/pip/wheels/2a/88/b2/587b498e2caa887707a63d0ed7d7f4beca27f5034640382845\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-2.5.8\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1749049197800,"user":{"displayName":"전진구","userId":"15391197455953273384"},"user_tz":-540},"id":"VwxXRs6dA4xd","outputId":"1ac3416b-0ac9-41ae-fc63-5011d743adef"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Liquid/evaluation\n"]}],"source":["%cd /content/drive/MyDrive/Liquid/evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OedZwINKN-uN","outputId":"688d31cd-b621-4de2-8b49-2273f8e17a0e","executionInfo":{"status":"ok","timestamp":1748953091910,"user_tz":-540,"elapsed":131479,"user":{"displayName":"전진구","userId":"15391197455953273384"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","1. 순수 언어 대화 (Text-to-Text) 테스트 시작...\n","The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","0it [00:00, ?it/s]\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [01:11<00:00, 17.84s/it]\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","2025-06-03 12:17:19.884251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1748953039.909097    7019 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1748953039.916792    7019 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","This adventure in a tale of adventure in the world.\n","\n","Where a brave cat warrior takes on a quest,\n","Into a land of wonder and mystery\n","Where he faces the unknown and sees,\n","A world of wonder and mystery.\n","\n","With courage and determination in his heart and wings,\n","The cat warrior embarks upon his journey.\n","\n","Into the heart of a dangerous land of fire and ice,\n","The cat warrior faces the challenge head on.\n","\n","With a fierce determination and a fierce spirit,\n","The cat warrior rises and becomes a legend.\n","\n","For his courage and his bravery, the cat warrior is feared.\n","\n","In the end, the cat warrior finds peace in his heart and mind,\n","For his journey has given him a sense of peace and strength.\n","\n","So let us remember the cat warrior's tale,\n","And the journey he took on to become a legend.\n","\n"]}],"source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"1. 순수 언어 대화 (Text-to-Text) 테스트 시작...\")\n","!python inference_t2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"Write a poem about a cat warrior's adventure.\" \\\n","    --load_8bit"]},{"cell_type":"markdown","source":["이 세상 모험 이야기 속 모험.\n","\n","용감한 고양이 전사가 임무를 맡아,\n","경이와 신비의 땅으로 들어가네.\n","그곳에서 미지의 세계와 마주하고 보았네,\n","경이와 신비의 세계를.\n","\n","가슴과 날개에 용기와 결의를 품고,\n","고양이 전사는 여정을 시작하네.\n","\n","불과 얼음의 위험한 땅 심장부로,\n","고양이 전사는 정면으로 도전에 맞서네.\n","\n","맹렬한 결의와 맹렬한 정신으로,\n","고양이 전사는 일어나 전설이 되네.\n","\n","그의 용기와 용맹함으로 고양이 전사는 두려움의 대상이 되었네.\n","\n","마침내 고양이 전사는 마음과 정신에 평화를 찾았네,\n","그의 여정이 그에게 평화와 힘을 주었기에.\n","\n","그러니 우리 고양이 전사의 이야기를 기억하자,\n","그리고 그가 전설이 되기 위해 떠났던 여정을."],"metadata":{"id":"18JiWdTxzt0s"}},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"draw a cat warrior's adventure.\" \\\n","    --load_8bit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bL69zEzRm0y","executionInfo":{"status":"ok","timestamp":1748959916147,"user_tz":-540,"elapsed":341223,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"2e9af48d-7b02-45a5-8e76-23086ded8381"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:14<00:00,  3.70s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","  0% 0/1024 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","2025-06-03 14:06:37.112278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1748959597.130728   35166 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1748959597.136295   35166 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","  0% 1/1024 [00:03<1:05:34,  3.85s/it]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","100% 1024/1024 [05:17<00:00,  3.22it/s]\n","Saving 3 generated images...\n","Starting from index: 4\n","Saved: samples/t2i/sample_4.jpg\n","Saved: samples/t2i/sample_5.jpg\n","Saved: samples/t2i/sample_6.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","# 16bit 테스트\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"draw a cat warrior's adventure.\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bEMEgrgoNl5","executionInfo":{"status":"ok","timestamp":1749002260167,"user_tz":-540,"elapsed":259559,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"68c4181b-7174-4186-c3ae-24c96a8e8c8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [02:44<00:00, 41.13s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","100% 1024/1024 [01:03<00:00, 16.04it/s]\n","Saving 3 generated images...\n","Starting from index: 7\n","Saved: samples/t2i/sample_7.jpg\n","Saved: samples/t2i/sample_8.jpg\n","Saved: samples/t2i/sample_9.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","# 16bit 테스트\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"Generate a image about a dog tunes a violin.\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wa2Jg1PmrjK6","executionInfo":{"status":"ok","timestamp":1749002828834,"user_tz":-540,"elapsed":83256,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"529ab6a5-265b-485d-a92b-452696fd8c60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.34s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","100% 1024/1024 [01:02<00:00, 16.43it/s]\n","Saving 3 generated images...\n","Starting from index: 10\n","Saved: samples/t2i/sample_10.jpg\n","Saved: samples/t2i/sample_11.jpg\n","Saved: samples/t2i/sample_12.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","# 16bit 테스트\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"An open ancient book with intricate patterns and symbols lies on a wooden surface. Two glowing amber crystals rest on the right page. Generate a image based on this description.\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_yPTVHustt9","executionInfo":{"status":"ok","timestamp":1749003064903,"user_tz":-540,"elapsed":83970,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"3455a74d-972b-49c4-df42-234f93c9a311"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.43s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","100% 1024/1024 [01:02<00:00, 16.40it/s]\n","Saving 3 generated images...\n","Starting from index: 13\n","Saved: samples/t2i/sample_13.jpg\n","Saved: samples/t2i/sample_14.jpg\n","Saved: samples/t2i/sample_15.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","# 16bit 테스트\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"young blue dragon with horn lightning in the style of dd fantasy full body\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXqLyzTftyOF","executionInfo":{"status":"ok","timestamp":1749003397616,"user_tz":-540,"elapsed":83846,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"fdd261bc-7238-4af9-dabd-dd887c66f88b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.40s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","100% 1024/1024 [01:02<00:00, 16.33it/s]\n","Saving 3 generated images...\n","Starting from index: 16\n","Saved: samples/t2i/sample_16.jpg\n","Saved: samples/t2i/sample_17.jpg\n","Saved: samples/t2i/sample_18.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"2. 이미지 생성 (Text-to-Image) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","# 16bit 테스트\n","!python inference_t2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --prompt \"young blue dragon with horn lightning in the style of dd fantasy full body\" \\\n","    --load_8bit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6l6shVXxTV4","executionInfo":{"status":"ok","timestamp":1749004518671,"user_tz":-540,"elapsed":315089,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"cb8d3376-b87d-4098-d344-2f60c9507abf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","2. 이미지 생성 (Text-to-Image) 테스트 시작...\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:14<00:00,  3.71s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","  0% 0/1024 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","2025-06-04 02:30:25.964953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749004225.983621   11840 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749004225.989157   11840 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","  0% 1/1024 [00:03<1:05:54,  3.87s/it]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","100% 1024/1024 [04:50<00:00,  3.53it/s]\n","Saving 3 generated images...\n","Starting from index: 19\n","Saved: samples/t2i/sample_19.jpg\n","Saved: samples/t2i/sample_20.jpg\n","Saved: samples/t2i/sample_21.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/t2i/sample_3.jpg \\\n","    --prompt \"Judge if the cat warrior from the photo can win against the dog warrior.\" \\\n","    --load_8bit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04chRtVFx0fT","executionInfo":{"status":"ok","timestamp":1748955764588,"user_tz":-540,"elapsed":89507,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"c8ecfd85-f47a-4f4e-a1a2-6d193aff9a3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:14<00:00,  3.68s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","Judge if the cat warrior from the photo can win against the dog warrior.<end_of_turn>\n","<start_of_turn>model\n","\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","2025-06-03 13:01:38.195921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1748955698.221594   18376 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1748955698.229355   18376 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","In the context of this image, the \"cat warrior\" and the \"dog warrior\" are represented by anthropomorphic animals equipped for combat, akin to medieval knights, with human-like weapons and armor. However, the question pertains to a hypothetical real-world scenario, asking if a cat warrior could defeat a dog warrior in a battle. \n","\n","In reality, there are no reliable records of such mythical conflicts, nor is there any evidence that cats or dogs have natural combat abilities to match one another in sustained battles. Typically, fighting animals do not engage in such confrontations in nature due to various physiological differences that would make one an immediate threat to the other. Domesticated animals, such as cats and dogs, do engage in playful fights as part of their social interaction, which serves no biological purpose beyond establishing play hierarchies and dominance.\n","\n","Given that the image is a fictional and playful representation with no basis in biological or historical evidence, it cannot be used to form a factual basis for determining the outcome of a potential battle between these two characters. The question is, therefore, based on a flawed premise that does not align with the observable facts about domestic animals' behaviors and abilities.\n","\n"]}]},{"cell_type":"markdown","source":["이 그림의 맥락에서 '고양이 전사'와 '강아지 전사'는 중세 기사와 흡사하게 인간형 무기와 갑옷으로 전투 채비를 갖춘 의인화된 동물로 묘사됩니다. 하지만 이 질문은 고양이 전사가 실제 전투에서 강아지 전사를 이길 수 있을지 여부에 대한, 즉 현실 세계를 가정한 가상 시나리오에 관한 것입니다.\n","\n","현실적으로 이러한 전설 속 싸움에 대한 믿을 만한 기록은 없으며, 고양이나 개가 지속적인 전투에서 서로 맞설 만한 타고난 전투 능력을 지녔다는 증거도 없습니다. 일반적으로 동물들은 어느 한쪽이 상대에게 즉각적인 위협이 될 수 있는 다양한 생리적 차이 때문에 자연 상태에서는 이와 같은 대결을 하지 않습니다. 고양이나 개와 같은 길들여진 동물들은 사회적 상호작용의 일환으로 장난삼아 싸우기는 하지만, 이는 놀이 서열이나 우위를 정하는 것 외에는 어떠한 생물학적 의미도 갖지 않습니다.\n","\n","이 그림이 생물학적 또는 역사적 증거에 근거하지 않은 허구적이고 장난스러운 묘사라는 점을 고려하면, 이는 두 캐릭터 간의 가상 전투 결과를 판단하기 위한 사실적 근거로 사용될 수 없습니다. 그러므로 이 질문은 길들여진 동물들의 행동과 능력에 관해 관찰되는 사실과 부합하지 않는, 결함 있는 전제에 기반하고 있습니다."],"metadata":{"id":"ORFhZi4449Rb"}},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/bycle.png \\\n","    --prompt \"How many motorcycles are there in the image?\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPn6EQeVtEq2","executionInfo":{"status":"ok","timestamp":1749003238869,"user_tz":-540,"elapsed":30377,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"f7707e61-a4cf-4a57-d9fd-9a7314af8a1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.38s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","How many motorcycles are there in the image?<end_of_turn>\n","<start_of_turn>model\n","\n","2025-06-04 02:13:50.958341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749003230.984145    7557 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749003230.992318    7557 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","There are two motorcycles in the image.\n","\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/ive.png \\\n","    --prompt \"How many people are there in the image?\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xD7oH9a2faVE","executionInfo":{"status":"ok","timestamp":1749049897379,"user_tz":-540,"elapsed":28680,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"eaa390d4-d761-42b4-bff0-14592d2cd05a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.40s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","How many people are there in the image?<end_of_turn>\n","<start_of_turn>model\n","\n","2025-06-04 15:11:30.671549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749049890.695885    6310 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749049890.703482    6310 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","There are six people in the image.\n","\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/city.png \\\n","    --prompt \"Describe this image in detail\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nP_YWLeIuWrz","executionInfo":{"status":"ok","timestamp":1749003459731,"user_tz":-540,"elapsed":32406,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"ab0b4132-e1ca-4690-f0c7-306d2a8c5108"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.37s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","Describe this image in detail<end_of_turn>\n","<start_of_turn>model\n","\n","2025-06-04 02:17:27.545419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749003447.570813    8573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749003447.578674    8573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","The image captures the Kaaba, a significant religious site in Mecca, Saudi Arabia. From a high vantage point, the Kaaba, a black cube-shaped building, stands out prominently in the center of the frame. Its simplicity contrasts with the complex architecture of the surrounding buildings. The area around the Kaaba is a sea of people, their figures small but discernible, moving in a counter-clockwise direction around the holy site. The sky above is a clear blue, dotted with white clouds, and the setting sun casts a warm glow on the scene. The image is taken from an angle that provides a comprehensive view of the Kaaba and its surroundings, encapsulating the religious fervor and architectural grandeur of this world-renowned landmark.\n","\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/city.png \\\n","    --prompt \"Describe this image in detail\""],"metadata":{"id":"hjOxwTwTyQ_b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이 이미지는 사우디아라비아 메카에 있는 중요한 종교 유적인 카바를 포착한 것입니다. 높은 곳에서 바라본 카바는 검은색 정육면체 모양의 건물로, 프레임 중앙에 두드러지게 서 있습니다. 그 단순함은 주변 건물들의 복잡한 건축 양식과 대조를 이룹니다. 카바 주변은 수많은 사람들로 가득 차 있으며, 작지만 식별 가능한 인물들이 성지를 중심으로 시계 반대 방향으로 움직이고 있습니다. 위 하늘은 맑고 푸르며 흰 구름이 점점이 흩어져 있고, 지는 해는 장면에 따뜻한 빛을 드리웁니다. 이미지는 카바와 그 주변 환경을 포괄적으로 볼 수 있는 각도에서 촬영되어, 이 세계적으로 유명한 랜드마크의 종교적 열정과 건축적 웅장함을 담아내고 있습니다."],"metadata":{"id":"FEZUTs6tvZgR"}},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/Gwanghwamun.png \\\n","    --prompt \"Describe this image in detail\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIHCFVDTwuuZ","executionInfo":{"status":"ok","timestamp":1749004137424,"user_tz":-540,"elapsed":35030,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"4c9f0557-0541-4d89-c990-9e8978e39fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.38s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","Describe this image in detail<end_of_turn>\n","<start_of_turn>model\n","\n","2025-06-04 02:28:42.796550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749004122.823197   11462 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749004122.831492   11462 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","The image showcases the stunning view of the Changdeokgung Palace in Seoul, South Korea. The palace, bathed in the soft glow of warm yellow lights, stands majestically against the backdrop of a deep blue night sky. The traditional Korean-style architecture of the palace, with its distinctive curved roofs and ornate decorations, is beautifully illuminated, highlighting the intricate details of the woodwork and tilework. The perspective of the photo, taken from a low angle, enhances the grandeur of the palace, making it appear as if it's soaring into the sky. In the foreground, a few potted plants add a touch of greenery to the scene, while the silhouettes of people in the background lend a sense of scale and liveliness to the image. The image code 'sa_1170' could be a reference to the specific viewpoint or angle from which this photo was taken. Overall, the image captures the serene beauty of this historic landmark, presenting a captivating glimpse into South Korea's rich cultural heritage.\n","\n"]}]},{"cell_type":"markdown","source":["이 이미지는 대한민국 서울에 있는 창덕궁의 멋진 풍경을 보여줍니다. 부드러운 노란색 조명의 따뜻한 빛을 받고 있는 궁궐은 짙푸른 밤하늘을 배경으로 장엄하게 서 있습니다. 독특한 곡선 지붕과 화려한 장식이 특징인 전통 한국식 궁궐 건축 양식이 아름답게 조명되어 목조와 기와 작업의 복잡한 세부 사항을 강조합니다. 낮은 각도에서 촬영된 사진의 구도는 궁궐의 웅장함을 더욱 돋보이게 하여 마치 하늘로 솟아오르는 듯한 느낌을 줍니다. 전경에는 몇 개의 화분이 장면에 녹색을 더하고 있으며, 배경에 있는 사람들의 실루엣은 이미지에 규모감과 생동감을 부여합니다. 이미지 코드 'sa_1170'은 이 사진이 촬영된 특정 시점이나 각도를 참조하는 것일 수 있습니다. 전반적으로 이 이미지는 이 역사적인 랜드마크의 고요한 아름다움을 포착하여 대한민국의 풍부한 문화유산을 매혹적으로 엿볼 수 있게 해줍니다."],"metadata":{"id":"1mNuTNQmx6h4"}},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"3. 이미지 이해 (Image-to-Text) 테스트 시작...\")\n","# README에 있는 명령어와 사용자님이 언급하신 프롬프트를 사용합니다.\n","!python inference_i2t.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/Gwanghwamun.png \\\n","    --prompt \"Describe this image in detail. It's a photo of Gwanghwamun Gate.\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULoNmgszy3eH","executionInfo":{"status":"ok","timestamp":1749004632167,"user_tz":-540,"elapsed":30381,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"26176340-764f-48ec-eb72-096d072dcca3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지 이해 (Image-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.42s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","<start_of_turn>user\n","<boi><image><eoi>\n","Describe this image in detail. It's a photo of Gwanghwamun Gate.<end_of_turn>\n","<start_of_turn>model\n","\n","2025-06-04 02:37:01.522661: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1749004621.547918   13698 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1749004621.555714   13698 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","The image depicts Gwanghwamun Gate during the night with the palace architecture lit up. The gate itself is a traditional Korean gate style, characterized by its curved eaves and symmetrical design. It's mounted on a wall with two red doors that are closed. Above the gate, there is a sign with Korean script underneath a series of eaves which extend on both sides, giving it a balanced appearance. Illuminated by floodlights, the gate stands out against the dark sky, and the photo captures the serene night atmosphere.\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VPqQ8AOVfQYx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이 이미지는 궁궐 건축물에 조명이 켜진 야간의 광화문을 묘사하고 있습니다. 광화문 자체는 곡선 형태의 처마와 대칭적인 디자인이 특징인 전통적인 한국식 문 스타일입니다. 문은 닫혀 있는 두 개의 붉은색 문이 있는 벽 위에 설치되어 있습니다. 문 위에는 처마 아래에 한글 현판이 있으며, 이 처마는 양쪽으로 뻗어 있어 균형 잡힌 모습을 보여줍니다. 투광 조명으로 밝혀진 문은 어두운 하늘을 배경으로 두드러지며, 사진은 고요한 밤의 분위기를 담아내고 있습니다."],"metadata":{"id":"YW0UfXqvze8l"}},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\")\n","!python inference_it2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/t2i/sample_2.jpg \\\n","    --prompt \"Using the cat warrior from the reference image, create an epic fantasy battle scene where this same cat warrior in armor fights against a fierce dog warrior with weapons, maintain the cat warrior's appearance and characteristics from the input image, dynamic action poses, medieval battlefield, dramatic lighting, high detail, concept art quality\" \\\n","    --cfg 10.0 \\\n","    --TopK 2048 \\\n","    --num_samples 1 \\\n","    --load_8bit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4KUL8R8142P","executionInfo":{"status":"ok","timestamp":1748959115158,"user_tz":-540,"elapsed":320475,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"7f72aecb-4221-4480-800a-743758f79eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","3. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\n","The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:15<00:00,  3.76s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","Input prompt:\n","<start_of_turn>user\n","<boi><image><eoi>\n","Using the cat warrior from the reference image, create an epic fantasy battle scene where this same cat warrior in armor fights against a fierce dog warrior with weapons, maintain the cat warrior's appearance and characteristics from the input image, dynamic action poses, medieval battlefield, dramatic lighting, high detail, concept art quality Generate a new image based on this.<end_of_turn>\n","<start_of_turn>model\n","\n","--------------------------------------------------\n","Input image VQ code shape: torch.Size([1024])\n","Input image VQ code range: 6 ~ 8168\n","--------------------------------------------------\n","Total input sequence length: 1105\n","Conditional length: 1105, Unconditional length: 3\n","Added 1102 padding tokens to unconditional input\n","Generating new image...\n","Full input shape: torch.Size([2, 1105])\n","Attention mask shape: torch.Size([2, 1105])\n","--------------------------------------------------\n","  0% 0/1024 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","2025-06-03 13:53:38.594358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1748958818.612798   31775 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1748958818.618405   31775 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","  0% 1/1024 [00:04<1:25:05,  4.99s/it]/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","100% 1024/1024 [04:56<00:00,  3.45it/s]\n","Saving 1 generated images...\n","Saved: samples/it2i/sample_0.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\")\n","# 16bit 테스트\n","!python inference_it2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/t2i/sample_2.jpg \\\n","    --prompt \"Using the cat warrior from the reference image, create an epic fantasy battle scene where this same cat warrior in armor fights against a fierce dog warrior with weapons, maintain the cat warrior's appearance and characteristics from the input image, dynamic action poses, medieval battlefield, dramatic lighting, high detail, concept art quality\" \\\n","    --cfg 10.0 \\\n","    --TopK 2048 \\\n","    --num_samples 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGJA45AYqhro","executionInfo":{"status":"ok","timestamp":1749002695847,"user_tz":-540,"elapsed":93485,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"c3119efb-a1d6-4664-90ff-f2b39f024e78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.29s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","Input prompt:\n","<start_of_turn>user\n","<boi><image><eoi>\n","Using the cat warrior from the reference image, create an epic fantasy battle scene where this same cat warrior in armor fights against a fierce dog warrior with weapons, maintain the cat warrior's appearance and characteristics from the input image, dynamic action poses, medieval battlefield, dramatic lighting, high detail, concept art quality Generate a new image based on this.<end_of_turn>\n","<start_of_turn>model\n","\n","--------------------------------------------------\n","Input image VQ code shape: torch.Size([1024])\n","Input image VQ code range: 6 ~ 8168\n","--------------------------------------------------\n","Total input sequence length: 1105\n","Conditional length: 1105, Unconditional length: 3\n","Added 1102 padding tokens to unconditional input\n","Generating new image...\n","Full input shape: torch.Size([6, 1105])\n","Attention mask shape: torch.Size([6, 1105])\n","--------------------------------------------------\n","100% 1024/1024 [01:12<00:00, 14.12it/s]\n","Saving 3 generated images...\n","Starting from index: 2\n","Saved: samples/it2i/sample_2.jpg\n","Saved: samples/it2i/sample_3.jpg\n","Saved: samples/it2i/sample_4.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\")\n","# 16bit 테스트\n","!python inference_it2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/t2i/sample_2.jpg \\\n","    --prompt \"This image is a photo of a cat warrior, please revise the style of this photo to have a cyberpunk feel.\" \\\n","    --cfg 10.0 \\\n","    --TopK 2048 \\\n","    --num_samples 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyXBytkecgRk","executionInfo":{"status":"ok","timestamp":1749049455302,"user_tz":-540,"elapsed":247617,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"cfaee4e1-d21f-4fb2-bba6-6e813ccb6c52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [02:38<00:00, 39.51s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","Input prompt:\n","<start_of_turn>user\n","<boi><image><eoi>\n","This image is a photo of a cat warrior, please revise the style of this photo to have a cyberpunk feel. Generate a new image based on this.<end_of_turn>\n","<start_of_turn>model\n","\n","--------------------------------------------------\n","Input image VQ code shape: torch.Size([1024])\n","Input image VQ code range: 6 ~ 8168\n","--------------------------------------------------\n","Total input sequence length: 1067\n","Conditional length: 1067, Unconditional length: 3\n","Added 1064 padding tokens to unconditional input\n","Generating new image...\n","Full input shape: torch.Size([6, 1067])\n","Attention mask shape: torch.Size([6, 1067])\n","--------------------------------------------------\n","100% 1024/1024 [01:11<00:00, 14.25it/s]\n","Saving 3 generated images...\n","Starting from index: 5\n","Saved: samples/it2i/sample_5.jpg\n","Saved: samples/it2i/sample_6.jpg\n","Saved: samples/it2i/sample_7.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":["# 현재 작업 디렉토리가 /content/Liquid/evaluation 인지 확인\n","print(\"현재 작업 디렉토리:\")\n","!pwd\n","print(\"-\" * 30)\n","\n","print(\"4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\")\n","# 16bit 테스트\n","!python inference_it2i.py \\\n","    --model_path /content/drive/MyDrive/Liquid/models/Liquid_V1_7B \\\n","    --image_path samples/t2i/sample_2.jpg \\\n","    --prompt \"Revise the style of this photo to have a cyberpunk feel.\" \\\n","    --cfg 10.0 \\\n","    --TopK 2048 \\\n","    --num_samples 3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbToHcRZeNgq","executionInfo":{"status":"ok","timestamp":1749049578727,"user_tz":-540,"elapsed":93722,"user":{"displayName":"전진구","userId":"15391197455953273384"}},"outputId":"a48718e3-fef2-4cda-ea0a-e329979042c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["현재 작업 디렉토리:\n","/content/drive/MyDrive/Liquid/evaluation\n","------------------------------\n","4. 이미지+텍스트 -> 이미지 생성 (Image&text-to-Text) 테스트 시작...\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Gemma's activation function should be approximate GeLU and not exact GeLU.\n","Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","Loading checkpoint shards: 100% 4/4 [00:09<00:00,  2.35s/it]\n","VQModel loaded from chameleon/vqgan.ckpt\n","Input prompt:\n","<start_of_turn>user\n","<boi><image><eoi>\n","Revise the style of this photo to have a cyberpunk feel. Generate a new image based on this.<end_of_turn>\n","<start_of_turn>model\n","\n","--------------------------------------------------\n","Input image VQ code shape: torch.Size([1024])\n","Input image VQ code range: 6 ~ 8168\n","--------------------------------------------------\n","Total input sequence length: 1057\n","Conditional length: 1057, Unconditional length: 3\n","Added 1054 padding tokens to unconditional input\n","Generating new image...\n","Full input shape: torch.Size([6, 1057])\n","Attention mask shape: torch.Size([6, 1057])\n","--------------------------------------------------\n","100% 1024/1024 [01:12<00:00, 14.17it/s]\n","Saving 3 generated images...\n","Starting from index: 8\n","Saved: samples/it2i/sample_8.jpg\n","Saved: samples/it2i/sample_9.jpg\n","Saved: samples/it2i/sample_10.jpg\n","Image generation completed!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y7gwRh-beSXU"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNLz38FYUM46w8mln3n0I/b"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}